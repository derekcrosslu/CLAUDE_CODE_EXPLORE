{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Walk-Forward Validation - Statistical Arbitrage Strategy\n",
    "\n",
    "**Strategy**: Hypothesis 5 - Statistical Arbitrage Pairs Trading  \n",
    "**Project ID**: 26140717  \n",
    "**Optimized Sharpe**: 1.829  \n",
    "**Baseline Sharpe**: 0.127  \n",
    "\n",
    "## Optimized Parameters to Validate:\n",
    "- z_entry_threshold: 1.5\n",
    "- z_exit_threshold: 1.0\n",
    "- lookback_period: 30\n",
    "- position_size_per_pair: 0.40\n",
    "- max_holding_days: 30\n",
    "- stop_loss_z: 4.0\n",
    "\n",
    "## Approach:\n",
    "Uses QuantBook to:\n",
    "1. Access historical data for pairs (PNC/KBE, ARCC/AMLP, RBA/SMFG, ENB/WEC)\n",
    "2. Run Monte Carlo splits (random train/test periods)\n",
    "3. Execute strategy logic locally in Python\n",
    "4. Calculate Sharpe ratio for each period\n",
    "5. Analyze degradation (train vs test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport random\nfrom collections import Counter, deque\nimport json\n\n# LOCAL DEBUG MODE - Use mock QuantConnect API\nprint(\"=\"*70)\nprint(\"LOCAL DEBUG MODE - Using Mock QuantConnect API\")\nprint(\"=\"*70)\nfrom mock_quantbook import QuantBook, Resolution\n\n# Initialize QuantBook (mock)\nqb = QuantBook()\n\nprint(\"✓ Mock QuantConnect Research environment initialized\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== CONFIGURATION ====================\n\nconfig = {\n    'project_id': 26140717,\n    \n    # Pairs to trade\n    'pairs': [\n        {'long': 'PNC', 'short': 'KBE', 'name': 'PNC_KBE'},\n        {'long': 'ARCC', 'short': 'AMLP', 'name': 'ARCC_AMLP'},\n        {'long': 'RBA', 'short': 'SMFG', 'name': 'RBA_SMFG'},\n        {'long': 'ENB', 'short': 'WEC', 'name': 'ENB_WEC'}\n    ],\n    \n    # Total period for analysis\n    'total_period': {\n        'start': datetime(2022, 1, 1),\n        'end': datetime(2025, 10, 31)\n    },\n    \n    # Monte Carlo configuration\n    'train_test_split': 0.70,\n    'monte_carlo_runs': 20,  # Gradual scaling: 20 → 50 → 100 → ... → 1000+\n    'random_seed': 42,\n    \n    # Optimized parameters to test\n    'parameters': {\n        'z_entry_threshold': 1.5,\n        'z_exit_threshold': 1.0,\n        'lookback_period': 30,\n        'position_size_per_pair': 0.40,\n        'max_holding_days': 30,\n        'stop_loss_z': 4.0\n    },\n    \n    'baseline_sharpe': 1.829,\n    'initial_capital': 100000\n}\n\n# Set random seed\nif config['random_seed']:\n    random.seed(config['random_seed'])\n    np.random.seed(config['random_seed'])\n\nprint(\"Configuration:\")\nprint(f\"  Pairs: {len(config['pairs'])}\")\nprint(f\"  Period: {config['total_period']['start'].date()} to {config['total_period']['end'].date()}\")\nprint(f\"  Train/Test: {config['train_test_split']*100:.0f}%/{(1-config['train_test_split'])*100:.0f}%\")\nprint(f\"  Monte Carlo runs: {config['monte_carlo_runs']} (testing gradually toward 1000+)\")\nprint(f\"  Parameters: {config['parameters']}\")\nprint(f\"  Baseline Sharpe: {config['baseline_sharpe']:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SUBSCRIBE TO SECURITIES ====================\n",
    "\n",
    "print(\"Subscribing to securities...\")\n",
    "\n",
    "symbols = {}\n",
    "for pair in config['pairs']:\n",
    "    long_sym = qb.AddEquity(pair['long'], Resolution.Daily).Symbol\n",
    "    short_sym = qb.AddEquity(pair['short'], Resolution.Daily).Symbol\n",
    "    symbols[pair['name']] = {'long': long_sym, 'short': short_sym}\n",
    "    print(f\"  ✓ {pair['name']}: {pair['long']}/{pair['short']}\")\n",
    "\n",
    "print(f\"\\n✓ Subscribed to {len(symbols)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== DEBUG: DATA ALIGNMENT ISSUE ====================\n\nprint(\"=\"*70)\nprint(\"DEBUGGING DATA ALIGNMENT ISSUE\")\nprint(\"=\"*70)\nprint()\n\n# Test with one pair in a problematic test period\ntest_pair = config['pairs'][0]  # PNC/KBE\ntest_start = datetime(2025, 3, 23)  # From the error screenshot\ntest_end = datetime(2026, 5, 16)\n\nprint(f\"Testing {test_pair['name']}: {test_pair['long']}/{test_pair['short']}\")\nprint(f\"Period: {test_start.date()} to {test_end.date()} ({(test_end - test_start).days} days)\")\nprint()\n\n# Fetch data\nlong_hist = qb.History([symbols[test_pair['name']]['long']], test_start, test_end, Resolution.Daily)\nshort_hist = qb.History([symbols[test_pair['name']]['short']], test_start, test_end, Resolution.Daily)\n\nprint(f\"Raw fetch: Long={long_hist.shape[0]} rows, Short={short_hist.shape[0]} rows\")\nprint()\n\n# DISPLAY long history\nprint(\"Long history (full):\")\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\nlong_hist.head(len(long_hist))\n\nprint()\n\n# DISPLAY short history\nprint(\"Short history (full):\")\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\nshort_hist.head(len(short_hist))\n\nprint()\n\n# Extract close prices\nif isinstance(long_hist.index, pd.MultiIndex):\n    long_close = long_hist['close'].droplevel(0)\n    short_close = short_hist['close'].droplevel(0)\nelse:\n    long_close = long_hist['close']\n    short_close = short_hist['close']\n\nprint(f\"After extract: Long={len(long_close)}, Short={len(short_close)}\")\nprint(f\"Long NaN count: {long_close.isna().sum()}\")\nprint(f\"Short NaN count: {short_close.isna().sum()}\")\nprint()\n\n# Date overlap analysis\nlong_dates = set(long_close.index)\nshort_dates = set(short_close.index)\ncommon_dates = long_dates & short_dates\nlong_only = long_dates - short_dates\nshort_only = short_dates - long_dates\n\nprint(\"=\"*70)\nprint(\"DATE OVERLAP ANALYSIS\")\nprint(\"=\"*70)\nprint(f\"Long-only dates:  {len(long_only)}\")\nprint(f\"Short-only dates: {len(short_only)}\")\nprint(f\"Common dates:     {len(common_dates)}\")\nprint()\n\n# Current method\ndf_current = pd.DataFrame({'long_price': long_close, 'short_price': short_close})\nprint(\"=\"*70)\nprint(\"CURRENT METHOD (outer join + dropna)\")\nprint(\"=\"*70)\nprint(f\"Before dropna: {df_current.shape[0]} rows\")\nprint(f\"  Long NaN:    {df_current['long_price'].isna().sum()}\")\nprint(f\"  Short NaN:   {df_current['short_price'].isna().sum()}\")\nprint(f\"  Both valid:  {(df_current['long_price'].notna() & df_current['short_price'].notna()).sum()}\")\nprint()\nprint(\"df_current (full):\")\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\ndf_current.head(len(df_current))\n\nprint()\n\ndf_current_clean = df_current.dropna()\nprint(f\"After dropna:  {df_current_clean.shape[0]} rows\")\nprint()\nprint(\"df_current_clean (full):\")\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\ndf_current_clean.head(len(df_current_clean))\n\nprint()\n\n# Recommended method\nprint(\"=\"*70)\nprint(\"RECOMMENDED METHOD (reindex to common dates)\")\nprint(\"=\"*70)\ncommon_dates_sorted = sorted(common_dates)\ndf_recommended = pd.DataFrame({\n    'long_price': long_close.reindex(common_dates_sorted),\n    'short_price': short_close.reindex(common_dates_sorted)\n})\nprint(f\"After reindex: {df_recommended.shape[0]} rows\")\nprint(f\"  Long NaN:    {df_recommended['long_price'].isna().sum()}\")\nprint(f\"  Short NaN:   {df_recommended['short_price'].isna().sum()}\")\nprint()\nprint(\"df_recommended (full):\")\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\ndf_recommended.head(len(df_recommended))\n\nprint()\n\ndf_recommended_clean = df_recommended.dropna()\nprint(f\"After dropna:  {df_recommended_clean.shape[0]} rows\")\nprint()\nprint(\"df_recommended_clean (full):\")\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)\ndf_recommended_clean.head(len(df_recommended_clean))\n\nprint()\n\n# Diagnosis\nprint(\"=\"*70)\nprint(\"DIAGNOSIS\")\nprint(\"=\"*70)\nprint(f\"Expected (common dates):     {len(common_dates)}\")\nprint(f\"Current method result:       {df_current_clean.shape[0]}\")\nprint(f\"Recommended method result:   {df_recommended_clean.shape[0]}\")\nprint(f\"Improvement:                 +{df_recommended_clean.shape[0] - df_current_clean.shape[0]} rows\")\nprint()\n\nprint(\"=\"*70)\nprint(\"ROOT CAUSE\")\nprint(\"=\"*70)\nif len(long_only) > 0 or len(short_only) > 0:\n    print(f\"DATE MISALIGNMENT: {len(long_only) + len(short_only)} non-overlapping trading days\")\nelse:\n    print(\"NO DATE MISALIGNMENT\")\n\nif long_close.isna().sum() > 0 or short_close.isna().sum() > 0:\n    print(f\"NaN VALUES: Long has {long_close.isna().sum()} NaN, Short has {short_close.isna().sum()} NaN\")\nelse:\n    print(\"NO NaN VALUES\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "source": "# ==================== HELPER FUNCTIONS ====================\n\ndef generate_random_split(start_date, end_date, train_pct, seed=None):\n    \"\"\"Generate random train/test split for Monte Carlo\"\"\"\n    if seed is not None:\n        random.seed(seed)\n    \n    total_days = (end_date - start_date).days\n    train_days = int(total_days * train_pct)\n    test_days = total_days - train_days\n    \n    # Random start for training window\n    max_offset = test_days\n    offset = random.randint(0, max(0, max_offset))\n    \n    train_start = start_date + timedelta(days=offset)\n    train_end = train_start + timedelta(days=train_days)\n    test_start = train_end + timedelta(days=1)\n    test_end = train_start + timedelta(days=total_days)\n    \n    return train_start, train_end, test_start, test_end\n\n\ndef calculate_spread(long_prices, short_prices):\n    \"\"\"Calculate spread between two price series\"\"\"\n    return np.log(long_prices) - np.log(short_prices)\n\n\ndef calculate_zscore(spread, lookback):\n    \"\"\"Calculate z-score using rolling window\"\"\"\n    if len(spread) < lookback:\n        return pd.Series([np.nan] * len(spread), index=spread.index)\n    \n    rolling_mean = spread.rolling(window=lookback).mean()\n    rolling_std = spread.rolling(window=lookback).std(ddof=1)\n    \n    zscore = (spread - rolling_mean) / rolling_std\n    return zscore\n\n\ndef simulate_strategy(data, params):\n    \"\"\"\n    Simulate statistical arbitrage strategy on historical data\n    \n    Args:\n        data: Dict of DataFrames with price data for each pair\n        params: Strategy parameters\n    \n    Returns:\n        equity_curve: Daily portfolio values\n        trades: List of trade records\n    \"\"\"\n    capital = config['initial_capital']\n    equity_curve = []\n    trades = []\n    \n    # Get all dates (union of all pair dates)\n    all_dates = sorted(set().union(*[set(df.index) for df in data.values()]))\n    \n    # Track positions for each pair\n    positions = {pair['name']: None for pair in config['pairs']}\n    \n    for date in all_dates:\n        daily_pnl = 0\n        \n        # Process each pair\n        for pair in config['pairs']:\n            pair_name = pair['name']\n            df = data[pair_name]\n            \n            if date not in df.index:\n                continue\n            \n            # Get current prices and z-score\n            current_data = df.loc[:date]\n            if len(current_data) < params['lookback_period']:\n                continue\n            \n            long_price = df.loc[date, 'long_price']\n            short_price = df.loc[date, 'short_price']\n            z_score = df.loc[date, 'zscore']\n            \n            if np.isnan(z_score):\n                continue\n            \n            pos = positions[pair_name]\n            \n            # Check exit conditions\n            if pos is not None:\n                days_held = (date - pos['entry_date']).days\n                \n                # Calculate current P&L\n                if pos['direction'] == 'long_spread':\n                    pnl = (long_price / pos['entry_long'] - 1) * pos['long_shares'] * pos['entry_long']\n                    pnl -= (short_price / pos['entry_short'] - 1) * pos['short_shares'] * pos['entry_short']\n                else:\n                    pnl = (short_price / pos['entry_short'] - 1) * pos['short_shares'] * pos['entry_short']\n                    pnl -= (long_price / pos['entry_long'] - 1) * pos['long_shares'] * pos['entry_long']\n                \n                daily_pnl += pnl - pos['last_pnl']\n                pos['last_pnl'] = pnl\n                \n                # Exit conditions\n                exit_signal = False\n                exit_reason = None\n                \n                if abs(z_score) < params['z_exit_threshold']:\n                    exit_signal = True\n                    exit_reason = 'mean_reversion'\n                elif days_held >= params['max_holding_days']:\n                    exit_signal = True\n                    exit_reason = 'timeout'\n                elif abs(z_score) > params['stop_loss_z']:\n                    exit_signal = True\n                    exit_reason = 'stop_loss'\n                \n                if exit_signal:\n                    capital += pnl\n                    trades.append({\n                        'pair': pair_name,\n                        'entry_date': pos['entry_date'],\n                        'exit_date': date,\n                        'entry_z': pos['entry_z'],\n                        'exit_z': z_score,\n                        'pnl': pnl,\n                        'exit_reason': exit_reason,\n                        'days_held': days_held\n                    })\n                    positions[pair_name] = None\n            \n            # Check entry conditions (if no position)\n            if positions[pair_name] is None:\n                if abs(z_score) > params['z_entry_threshold']:\n                    # Calculate position sizes (dollar-neutral)\n                    pair_capital = capital * params['position_size_per_pair']\n                    \n                    if z_score > 0:  # Short spread (long short, short long)\n                        direction = 'short_spread'\n                        long_shares = pair_capital / (2 * long_price)\n                        short_shares = pair_capital / (2 * short_price)\n                    else:  # Long spread (long long, short short)\n                        direction = 'long_spread'\n                        long_shares = pair_capital / (2 * long_price)\n                        short_shares = pair_capital / (2 * short_price)\n                    \n                    positions[pair_name] = {\n                        'entry_date': date,\n                        'entry_z': z_score,\n                        'entry_long': long_price,\n                        'entry_short': short_price,\n                        'long_shares': long_shares,\n                        'short_shares': short_shares,\n                        'direction': direction,\n                        'last_pnl': 0\n                    }\n        \n        # Record equity\n        equity_curve.append({'date': date, 'equity': capital})\n    \n    return pd.DataFrame(equity_curve).set_index('date'), trades\n\n\ndef calculate_sharpe(equity_curve):\n    \"\"\"Calculate annualized Sharpe ratio\"\"\"\n    returns = equity_curve['equity'].pct_change().dropna()\n    if len(returns) == 0 or returns.std() == 0:\n        return 0.0\n    \n    sharpe = returns.mean() / returns.std() * np.sqrt(252)  # Annualized\n    return sharpe\n\n\nprint(\"✓ Helper functions loaded\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== MONTE CARLO WALK-FORWARD ====================\n\nprint(\"=\"*70)\nprint(\"MONTE CARLO WALK-FORWARD ANALYSIS - STATISTICAL ARBITRAGE\")\nprint(\"=\"*70)\nprint()\n\nresults = []\nerrors = []\n\nfor run in range(config['monte_carlo_runs']):\n    print(f\"\\n{'='*70}\")\n    print(f\"Monte Carlo Run {run + 1}/{config['monte_carlo_runs']}\")\n    print(f\"{'='*70}\")\n    \n    try:\n        # 1. Generate random train/test split\n        train_start, train_end, test_start, test_end = generate_random_split(\n            config['total_period']['start'],\n            config['total_period']['end'],\n            config['train_test_split'],\n            seed=run if config['random_seed'] else None\n        )\n        \n        print(f\"Training:  {train_start.date()} to {train_end.date()} ({(train_end - train_start).days} days)\")\n        print(f\"Testing:   {test_start.date()} to {test_end.date()} ({(test_end - test_start).days} days)\")\n        \n        # 2. Fetch historical data for TRAINING period\n        print(f\"\\nFetching training data...\")\n        train_data = {}\n        for pair in config['pairs']:\n            # Fetch history - use list with single symbol to get clean DataFrame\n            long_hist = qb.History([symbols[pair['name']]['long']], train_start, train_end, Resolution.Daily)\n            short_hist = qb.History([symbols[pair['name']]['short']], train_start, train_end, Resolution.Daily)\n            \n            if long_hist.empty or short_hist.empty:\n                print(f\"  ⚠ Skipping {pair['name']}: no data\")\n                continue\n            \n            # Extract close prices - handle multi-index if present\n            if isinstance(long_hist.index, pd.MultiIndex):\n                long_close = long_hist['close'].droplevel(0)\n                short_close = short_hist['close'].droplevel(0)\n            else:\n                long_close = long_hist['close']\n                short_close = short_hist['close']\n            \n            # Create aligned DataFrame\n            df = pd.DataFrame({\n                'long_price': long_close,\n                'short_price': short_close\n            }).dropna()\n            \n            # Only require lookback period worth of data\n            if len(df) < config['parameters']['lookback_period']:\n                print(f\"  ⚠ Skipping {pair['name']}: insufficient data ({len(df)} rows, need {config['parameters']['lookback_period']})\")\n                continue\n            \n            # Calculate spread and z-score\n            df['spread'] = np.log(df['long_price']) - np.log(df['short_price'])\n            df['zscore'] = calculate_zscore(df['spread'], config['parameters']['lookback_period'])\n            \n            train_data[pair['name']] = df\n            print(f\"  ✓ {pair['name']}: {len(df)} days\")\n        \n        if len(train_data) == 0:\n            raise ValueError(\"No training data available for any pair\")\n        \n        print(f\"  ✓ Fetched data for {len(train_data)} pairs\")\n        \n        # 3. Run strategy on TRAINING data\n        print(f\"Running strategy on training period...\")\n        train_equity, train_trades = simulate_strategy(train_data, config['parameters'])\n        train_sharpe = calculate_sharpe(train_equity)\n        print(f\"  ✓ Training Sharpe: {train_sharpe:.3f} ({len(train_trades)} trades)\")\n        \n        # 4. Fetch historical data for TESTING period\n        print(f\"\\nFetching testing data...\")\n        test_data = {}\n        for pair in config['pairs']:\n            # Fetch history\n            long_hist = qb.History([symbols[pair['name']]['long']], test_start, test_end, Resolution.Daily)\n            short_hist = qb.History([symbols[pair['name']]['short']], test_start, test_end, Resolution.Daily)\n            \n            if long_hist.empty or short_hist.empty:\n                print(f\"  ⚠ Skipping {pair['name']}: no data\")\n                continue\n            \n            # Extract close prices\n            if isinstance(long_hist.index, pd.MultiIndex):\n                long_close = long_hist['close'].droplevel(0)\n                short_close = short_hist['close'].droplevel(0)\n            else:\n                long_close = long_hist['close']\n                short_close = short_hist['close']\n            \n            # Create aligned DataFrame\n            df = pd.DataFrame({\n                'long_price': long_close,\n                'short_price': short_close\n            }).dropna()\n            \n            # Only require lookback period worth of data\n            if len(df) < config['parameters']['lookback_period']:\n                print(f\"  ⚠ Skipping {pair['name']}: insufficient data ({len(df)} rows, need {config['parameters']['lookback_period']})\")\n                continue\n            \n            # Calculate spread and z-score\n            df['spread'] = np.log(df['long_price']) - np.log(df['short_price'])\n            df['zscore'] = calculate_zscore(df['spread'], config['parameters']['lookback_period'])\n            \n            test_data[pair['name']] = df\n            print(f\"  ✓ {pair['name']}: {len(df)} days\")\n        \n        if len(test_data) == 0:\n            raise ValueError(\"No testing data available for any pair\")\n        \n        print(f\"  ✓ Fetched data for {len(test_data)} pairs\")\n        \n        # 5. Run strategy on TESTING data\n        print(f\"Running strategy on testing period...\")\n        test_equity, test_trades = simulate_strategy(test_data, config['parameters'])\n        test_sharpe = calculate_sharpe(test_equity)\n        print(f\"  ✓ Testing Sharpe: {test_sharpe:.3f} ({len(test_trades)} trades)\")\n        \n        # 6. Calculate degradation\n        if train_sharpe > 0:\n            degradation = (train_sharpe - test_sharpe) / train_sharpe\n        else:\n            degradation = 1.0\n        \n        print(f\"  Degradation: {degradation*100:.1f}%\")\n        \n        # Store results\n        results.append({\n            'run': run + 1,\n            'train_start': train_start,\n            'train_end': train_end,\n            'test_start': test_start,\n            'test_end': test_end,\n            'train_sharpe': float(train_sharpe),\n            'test_sharpe': float(test_sharpe),\n            'degradation': float(degradation),\n            'train_trades': len(train_trades),\n            'test_trades': len(test_trades)\n        })\n        \n        print(f\"  ✓ Run {run + 1} complete\")\n        \n    except Exception as e:\n        import traceback\n        error_msg = str(e)\n        traceback_str = traceback.format_exc()\n        print(f\"  ✗ Error in run {run + 1}: {error_msg}\")\n        print(f\"  Traceback:\\n{traceback_str}\")\n        errors.append({'run': run + 1, 'error': error_msg, 'traceback': traceback_str})\n        continue\n\nprint(f\"\\n{'='*70}\")\nprint(f\"Monte Carlo Walk-Forward Complete\")\nprint(f\"  Successful runs: {len(results)}/{config['monte_carlo_runs']}\")\nprint(f\"  Failed runs: {len(errors)}/{config['monte_carlo_runs']}\")\nprint(f\"{'='*70}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== ANALYSIS ====================\n\nif len(results) == 0:\n    print(\"✗ No successful runs to analyze\")\nelse:\n    df_results = pd.DataFrame(results)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"AGGREGATE RESULTS\")\n    print(\"=\"*70)\n    \n    # Basic statistics\n    mean_train = df_results['train_sharpe'].mean()\n    std_train = df_results['train_sharpe'].std()\n    mean_test = df_results['test_sharpe'].mean()\n    std_test = df_results['test_sharpe'].std()\n    mean_deg = df_results['degradation'].mean()\n    std_deg = df_results['degradation'].std()\n    \n    print(f\"\\nPerformance Metrics:\")\n    print(f\"  Baseline Sharpe (original):  {config['baseline_sharpe']:.3f}\")\n    print(f\"  Mean Training Sharpe:         {mean_train:.3f} ± {std_train:.3f}\")\n    print(f\"  Mean Testing Sharpe:          {mean_test:.3f} ± {std_test:.3f}\")\n    print(f\"  Mean Degradation:             {mean_deg*100:.1f}% ± {std_deg*100:.1f}%\")\n    \n    # ==================== BETTER OVERFITTING INDICATORS ====================\n    \n    print(f\"\\n\" + \"=\"*70)\n    print(\"OVERFITTING INDICATORS\")\n    print(\"=\"*70)\n    \n    # 1. Test Sharpe Stability (Coefficient of Variation)\n    test_sharpe_cv = (std_test / mean_test) if mean_test != 0 else float('inf')\n    print(f\"\\n1. Test Sharpe Stability:\")\n    print(f\"   Coefficient of Variation: {test_sharpe_cv:.2f}\")\n    print(f\"   Interpretation: {'STABLE' if test_sharpe_cv < 0.5 else 'UNSTABLE' if test_sharpe_cv < 1.0 else 'HIGHLY UNSTABLE'}\")\n    print(f\"   (Lower is better: <0.5 stable, 0.5-1.0 moderate, >1.0 unstable)\")\n    \n    # 2. Walk-Forward Efficiency\n    wf_efficiency = mean_test / mean_train if mean_train != 0 else 0\n    print(f\"\\n2. Walk-Forward Efficiency:\")\n    print(f\"   OOS Sharpe / IS Sharpe: {wf_efficiency:.1%}\")\n    print(f\"   Interpretation: {'EXCELLENT' if wf_efficiency > 0.80 else 'GOOD' if wf_efficiency > 0.60 else 'ACCEPTABLE' if wf_efficiency > 0.40 else 'WEAK' if wf_efficiency > 0.25 else 'SEVERE OVERFIT'}\")\n    print(f\"   (Expected: 25-80% for robust strategies)\")\n    \n    # 3. Test Sharpe vs Baseline\n    test_vs_baseline = (mean_test - config['baseline_sharpe']) / config['baseline_sharpe'] if config['baseline_sharpe'] != 0 else 0\n    print(f\"\\n3. Test Sharpe vs Baseline:\")\n    print(f\"   Difference: {test_vs_baseline:+.1%}\")\n    print(f\"   Mean Test: {mean_test:.3f} vs Baseline: {config['baseline_sharpe']:.3f}\")\n    if abs(test_vs_baseline) < 0.15:\n        print(f\"   Interpretation: CONSISTENT (within 15%)\")\n    elif test_vs_baseline > 0.15:\n        print(f\"   Interpretation: UNEXPECTED - Test > Baseline (possible data issue)\")\n    else:\n        print(f\"   Interpretation: DEGRADED - Test << Baseline\")\n    \n    # 4. Trade Count Analysis\n    mean_train_trades = df_results['train_trades'].mean()\n    mean_test_trades = df_results['test_trades'].mean()\n    min_test_trades = df_results['test_trades'].min()\n    print(f\"\\n4. Trade Count Analysis:\")\n    print(f\"   Mean Training Trades: {mean_train_trades:.1f}\")\n    print(f\"   Mean Testing Trades:  {mean_test_trades:.1f}\")\n    print(f\"   Min Testing Trades:   {min_test_trades}\")\n    print(f\"   Statistical Reliability: {'GOOD' if min_test_trades >= 30 else 'MARGINAL' if min_test_trades >= 15 else 'INSUFFICIENT'}\")\n    print(f\"   (Need 30+ trades for statistical significance)\")\n    \n    # 5. Consistency Analysis (% of runs with positive test Sharpe)\n    positive_test_pct = (df_results['test_sharpe'] > 0).sum() / len(df_results)\n    print(f\"\\n5. Consistency Analysis:\")\n    print(f\"   Runs with positive test Sharpe: {(df_results['test_sharpe'] > 0).sum()}/{len(df_results)} ({positive_test_pct:.0%})\")\n    print(f\"   Interpretation: {'HIGHLY CONSISTENT' if positive_test_pct >= 0.90 else 'CONSISTENT' if positive_test_pct >= 0.75 else 'MODERATE' if positive_test_pct >= 0.60 else 'INCONSISTENT'}\")\n    \n    # 6. Sample Size Assessment\n    print(f\"\\n6. Sample Size Assessment:\")\n    print(f\"   Total runs: {len(df_results)}\")\n    print(f\"   Statistical Power: {'ROBUST' if len(df_results) >= 1000 else 'ACCEPTABLE' if len(df_results) >= 100 else 'WEAK' if len(df_results) >= 50 else 'INSUFFICIENT' if len(df_results) >= 20 else 'ANECDOTAL'}\")\n    print(f\"   Minimum required: 1000+ runs\")\n    if len(df_results) < 1000:\n        print(f\"   ⚠ WARNING: Results not statistically reliable with {len(df_results)} runs\")\n    \n    # ==================== OVERALL ASSESSMENT ====================\n    \n    print(f\"\\n\" + \"=\"*70)\n    print(\"OVERALL ROBUSTNESS ASSESSMENT\")\n    print(\"=\"*70 + \"\\n\")\n    \n    # Calculate robustness score\n    score_components = []\n    \n    # Test Sharpe stability (weight: 20%)\n    if test_sharpe_cv < 0.5:\n        score_components.append(('Sharpe Stability', 20, 20))\n    elif test_sharpe_cv < 1.0:\n        score_components.append(('Sharpe Stability', 20, 10))\n    else:\n        score_components.append(('Sharpe Stability', 20, 0))\n    \n    # Walk-forward efficiency (weight: 30%)\n    if wf_efficiency > 0.80:\n        score_components.append(('WF Efficiency', 30, 30))\n    elif wf_efficiency > 0.60:\n        score_components.append(('WF Efficiency', 30, 25))\n    elif wf_efficiency > 0.40:\n        score_components.append(('WF Efficiency', 30, 15))\n    elif wf_efficiency > 0.25:\n        score_components.append(('WF Efficiency', 30, 5))\n    else:\n        score_components.append(('WF Efficiency', 30, 0))\n    \n    # Test vs baseline (weight: 20%)\n    if abs(test_vs_baseline) < 0.15:\n        score_components.append(('Test vs Baseline', 20, 20))\n    elif abs(test_vs_baseline) < 0.30:\n        score_components.append(('Test vs Baseline', 20, 10))\n    else:\n        score_components.append(('Test vs Baseline', 20, 0))\n    \n    # Trade count (weight: 15%)\n    if min_test_trades >= 30:\n        score_components.append(('Trade Count', 15, 15))\n    elif min_test_trades >= 15:\n        score_components.append(('Trade Count', 15, 8))\n    else:\n        score_components.append(('Trade Count', 15, 0))\n    \n    # Consistency (weight: 15%)\n    if positive_test_pct >= 0.90:\n        score_components.append(('Consistency', 15, 15))\n    elif positive_test_pct >= 0.75:\n        score_components.append(('Consistency', 15, 12))\n    elif positive_test_pct >= 0.60:\n        score_components.append(('Consistency', 15, 8))\n    else:\n        score_components.append(('Consistency', 15, 0))\n    \n    total_score = sum(s[2] for s in score_components)\n    max_score = sum(s[1] for s in score_components)\n    \n    print(\"Score Breakdown:\")\n    for name, max_pts, earned_pts in score_components:\n        print(f\"  {name}: {earned_pts}/{max_pts}\")\n    \n    print(f\"\\nTotal Robustness Score: {total_score}/{max_score} ({total_score/max_score*100:.0f}%)\")\n    \n    # Final decision\n    if len(df_results) < 1000:\n        decision = \"INSUFFICIENT_SAMPLES\"\n        reason = f\"Only {len(df_results)} runs (need 1000+ for validation)\"\n        recommendation = \"Continue scaling to 1000+ runs before making conclusion\"\n    elif total_score >= 85:\n        decision = \"ROBUST_STRATEGY\"\n        reason = f\"Score {total_score}/{max_score} - strong generalization\"\n        recommendation = \"Strategy passes validation - ready for paper trading\"\n    elif total_score >= 70:\n        decision = \"PROCEED_WITH_CAUTION\"\n        reason = f\"Score {total_score}/{max_score} - acceptable but not excellent\"\n        recommendation = \"Strategy shows reasonable robustness - additional validation recommended\"\n    elif total_score >= 50:\n        decision = \"WEAK_ROBUSTNESS\"\n        reason = f\"Score {total_score}/{max_score} - multiple concerns\"\n        recommendation = \"Strategy shows weak generalization - use with caution or re-optimize\"\n    else:\n        decision = \"ABANDON_STRATEGY\"\n        reason = f\"Score {total_score}/{max_score} - severe overfitting\"\n        recommendation = \"Strategy fails validation - consider new hypothesis\"\n    \n    print(f\"\\n✓ Decision: {decision}\")\n    print(f\"  Reason: {reason}\")\n    print(f\"  Recommendation: {recommendation}\")\n    \n    # Save results\n    output_data = {\n        'strategy': 'Statistical Arbitrage Pairs Trading',\n        'hypothesis_id': 5,\n        'project_id': config['project_id'],\n        'summary': {\n            'sample_size': len(results),\n            'successful_runs': len(results),\n            'failed_runs': len(errors),\n            'mean_train_sharpe': float(mean_train),\n            'std_train_sharpe': float(std_train),\n            'mean_test_sharpe': float(mean_test),\n            'std_test_sharpe': float(std_test),\n            'mean_degradation': float(mean_deg),\n            'std_degradation': float(std_deg),\n            'test_sharpe_cv': float(test_sharpe_cv),\n            'wf_efficiency': float(wf_efficiency),\n            'test_vs_baseline_pct': float(test_vs_baseline),\n            'mean_train_trades': float(mean_train_trades),\n            'mean_test_trades': float(mean_test_trades),\n            'min_test_trades': int(min_test_trades),\n            'positive_test_pct': float(positive_test_pct),\n            'robustness_score': int(total_score),\n            'max_score': int(max_score),\n            'decision': decision,\n            'reason': reason,\n            'recommendation': recommendation\n        },\n        'detailed_results': results,\n        'errors': errors\n    }\n    \n    filename = f\"walkforward_stat_arb_h5_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    with open(filename, 'w') as f:\n        json.dump(output_data, f, indent=2, default=str)\n    \n    print(f\"\\n✓ Results saved to: {filename}\")\n    print(\"\\n\" + \"=\"*70)\n    print(\"MONTE CARLO WALK-FORWARD ANALYSIS COMPLETE\")\n    print(\"=\"*70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}