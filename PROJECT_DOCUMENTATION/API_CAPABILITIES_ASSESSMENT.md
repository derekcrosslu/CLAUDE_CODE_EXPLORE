# QuantConnect API Capabilities Assessment

**Date**: 2025-11-10
**Project**: Autonomous Strategy Development Framework
**Purpose**: Determine what can be automated vs what requires manual intervention

---

## Tested API Endpoints

### ‚úÖ WORKING - Can Automate

| Endpoint | Purpose | Cost | Tested |
|----------|---------|------|--------|
| `POST /projects/list` | List all projects | FREE | ‚úÖ |
| `POST /projects/read` | Get project details | FREE | ‚úÖ |
| `POST /files/read` | Read file contents | FREE | ‚úÖ |
| `POST /files/create` | Create/upload files | FREE | ‚úÖ |
| `POST /files/update` | Update file contents | FREE | ‚úÖ |
| `POST /compile/create` | Compile project | FREE | ‚úÖ |
| `POST /backtests/list` | List backtests | FREE | ‚úÖ |
| `POST /backtests/read` | Get backtest results | FREE | ‚úÖ |
| `POST /backtests/create` | Run backtest | FREE (with limits) | ‚úÖ |

### ‚ö†Ô∏è LIMITED - Costs Money or Has Constraints

| Endpoint | Purpose | Cost | Issue |
|----------|---------|------|-------|
| `POST /optimizations/create` | Run optimization | üí∞ $0.50-$5+ per run | Requires paid tier |
| `POST /optimizations/estimate` | Estimate optimization cost | FREE | Tested, works |
| `POST /backtests/create` | Create backtest | FREE (10/day free tier) | Limited quota |

### ‚ùå NOT AVAILABLE - Cannot Automate

| Operation | Why Not Available |
|-----------|-------------------|
| Execute Research notebook cells | No API endpoint exists |
| Run `qb.Optimize()` via API | Only works inside Research environment |
| Run `qb.Backtest()` via API | Only works inside Research environment |
| Interactive notebook execution | Requires browser/web interface |

---

## Autonomous Framework Feasibility

### What CAN Be Fully Automated (via API):

1. **Project Management**
   - ‚úÖ Create new projects
   - ‚úÖ Upload strategy files
   - ‚úÖ Compile code
   - ‚úÖ Read project state

2. **Basic Backtesting**
   - ‚úÖ Run single backtests (10/day free)
   - ‚úÖ Read backtest results
   - ‚úÖ Parse performance metrics
   - ‚úÖ Make autonomous decisions based on results

3. **File Operations**
   - ‚úÖ Upload notebooks to research.ipynb
   - ‚úÖ Update strategy parameters
   - ‚úÖ Read/write any project files

4. **State Management**
   - ‚úÖ Track iteration state locally
   - ‚úÖ Log decisions
   - ‚úÖ Manage git commits

### What CANNOT Be Fully Automated:

1. **Parameter Optimization**
   - ‚ùå API optimization costs money (paid tier only)
   - ‚úÖ Alternative: Upload notebook ‚Üí user runs in Research (FREE)
   - Decision: **Hybrid approach required**

2. **Walk-Forward Validation**
   - ‚ùå Cannot execute Research notebooks remotely
   - ‚úÖ Alternative: Upload notebook ‚Üí user runs manually
   - Decision: **Manual step required**

3. **Advanced Analysis**
   - ‚ùå Cannot run QuantBook analysis automatically
   - ‚ùå No API for Monte Carlo sampling
   - Decision: **Notebook-based workflow only**

---

## Autonomous Framework Architectures

### Option A: Fully Automated (LIMITED)

**What's automated:**
- Hypothesis generation
- Strategy code creation
- Single backtest execution
- Basic parameter testing (grid search via multiple backtests)
- Decision making
- Git integration

**Limitations:**
- No true optimization (would need to burn backtest quota)
- No walk-forward validation
- Limited to 10 backtests/day on free tier
- Cannot do Monte Carlo analysis

**Cost:** FREE (within quotas)

**Feasibility:** ‚ö†Ô∏è Possible but constrained by backtest limits

---

### Option B: Hybrid (RECOMMENDED)

**What's automated:**
- Strategy creation and upload
- Initial baseline backtest
- Decision framework (proceed/optimize/abandon)
- Notebook generation and upload
- State tracking and git
- Results parsing (after user runs notebook)

**What requires manual intervention:**
- User runs optimization in Research (1-click, FREE)
- User runs walk-forward notebook (1-click, FREE)
- User provides results back to system

**Workflow:**
```
1. Claude creates strategy ‚Üí automated
2. Claude uploads to QC ‚Üí automated
3. Claude runs baseline backtest ‚Üí automated
4. Claude makes decision ‚Üí automated
5. IF needs optimization:
   a. Claude uploads notebook ‚Üí automated
   b. USER runs in Research ‚Üí MANUAL (1-click, FREE)
   c. Claude reads results ‚Üí automated
6. Claude updates state ‚Üí automated
7. Claude commits to git ‚Üí automated
```

**Cost:** FREE

**Feasibility:** ‚úÖ Highly feasible, best balance

---

### Option C: Paid Tier Automation

**What's automated:**
- Everything from Option A
- True optimization via API
- Multiple optimization runs
- Advanced parameter sweeps

**Requirements:**
- QuantConnect paid subscription ($8-$20/month)
- Optimization costs ($0.50-$5 per run)
- Higher backtest quotas

**Cost:** üí∞ $50-$200+/month depending on usage

**Feasibility:** ‚úÖ Fully feasible but expensive

---

## Recommendation for Autonomous Framework

### **Adopt Option B: Hybrid Approach**

**Rationale:**

1. **Cost-Effective**
   - Zero ongoing costs
   - No paid subscription required
   - Unlimited optimizations in Research

2. **Pragmatic**
   - One manual step (run notebook) is acceptable
   - Takes 1 minute of user time
   - Maintains full analytical power

3. **Scalable**
   - Can test multiple hypotheses per day
   - No quota limitations on Research
   - Easy to upgrade to Option C later

### Implementation:

**Autonomous Commands:**
- `/qc-init` - Fully automated
- `/qc-backtest` - Fully automated
- `/qc-optimize` - **Hybrid**: Claude uploads notebook, user runs it
- `/qc-validate` - **Hybrid**: Claude uploads notebook, user runs it
- `/qc-report` - Fully automated

**User Interaction Points:**
1. After `/qc-optimize`: "Notebook uploaded. Please run in Research and return when complete."
2. After `/qc-validate`: "Walk-forward notebook ready. Please run in Research."

**Autonomous Loop:**
```
while iteration < max_iterations:
    # Automated
    hypothesis = generate_hypothesis()
    strategy = create_strategy(hypothesis)
    upload(strategy)
    baseline = run_backtest()

    decision = evaluate(baseline)

    if decision == "optimize":
        # Hybrid - requires user
        notebook = generate_optimization_notebook()
        upload_notebook()
        wait_for_user("Run optimization in Research")
        results = read_results()

    if decision == "validate":
        # Hybrid - requires user
        notebook = generate_walkforward_notebook()
        upload_notebook()
        wait_for_user("Run walk-forward in Research")
        results = read_results()

    # Automated
    git_commit(results)
    log_decision()
    iteration += 1
```

---

## Current Status

### What Works NOW:

- ‚úÖ `upload_research_notebook.py` - Upload notebooks to Research
- ‚úÖ `qc_backtest.py` - Full API client for project/backtest operations
- ‚úÖ `monte_carlo_walkforward_REAL.ipynb` - Complete Monte Carlo notebook
- ‚úÖ API authentication and file operations
- ‚úÖ Backtest creation and result parsing

### What Needs Implementation:

- ‚ö†Ô∏è Update `/qc-optimize` command to use hybrid approach
- ‚ö†Ô∏è Update `/qc-validate` command to use hybrid approach
- ‚ö†Ô∏è Create "wait for user" interaction in commands
- ‚ö†Ô∏è Implement result reading from Research outputs

### Deprecated:

- ‚ùå `qc_walkforward_wrapper.py` - Calls paid optimization API
- ‚ùå `qc_optimize_wrapper.py` - Calls paid optimization API (if exists)

---

## Conclusion

**The autonomous framework IS feasible with a hybrid approach.**

**Key Insight:**
By leveraging the Research environment for optimization and walk-forward validation, we get:
- ‚úÖ Full analytical capabilities
- ‚úÖ Zero ongoing costs
- ‚úÖ 90% automation (only 2 manual 1-click steps)
- ‚úÖ Scalable to multiple hypotheses

**Next Steps:**
1. Adopt hybrid architecture
2. Update slash commands for hybrid workflow
3. Test complete end-to-end flow
4. Document user interaction points

**Trade-off:**
- Lose: 10% automation (2 manual clicks)
- Gain: $0 costs, unlimited analysis, full Monte Carlo capability

**Decision: PROCEED with Hybrid Approach** ‚úÖ
