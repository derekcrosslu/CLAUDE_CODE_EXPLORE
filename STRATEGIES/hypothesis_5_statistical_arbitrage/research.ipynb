{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Walk-Forward Validation - Statistical Arbitrage Strategy\n",
    "\n",
    "**Strategy**: Hypothesis 5 - Statistical Arbitrage Pairs Trading  \n",
    "**Project ID**: 26140717  \n",
    "**Optimized Sharpe**: 1.829  \n",
    "**Baseline Sharpe**: 0.127  \n",
    "\n",
    "## Optimized Parameters to Validate:\n",
    "- z_entry_threshold: 1.5\n",
    "- z_exit_threshold: 1.0\n",
    "- lookback_period: 30\n",
    "- position_size_per_pair: 0.40\n",
    "- max_holding_days: 30\n",
    "- stop_loss_z: 4.0\n",
    "\n",
    "## Approach:\n",
    "Uses QuantBook to:\n",
    "1. Access historical data for pairs (PNC/KBE, ARCC/AMLP, RBA/SMFG, ENB/WEC)\n",
    "2. Run Monte Carlo splits (random train/test periods)\n",
    "3. Execute strategy logic locally in Python\n",
    "4. Calculate Sharpe ratio for each period\n",
    "5. Analyze degradation (train vs test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ QuantConnect Research environment initialized\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from collections import Counter, deque\n",
    "import json\n",
    "\n",
    "# QuantConnect Research\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "\n",
    "# Initialize QuantBook\n",
    "qb = QuantBook()\n",
    "\n",
    "print(\"✓ QuantConnect Research environment initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Pairs: 4\n",
      "  Period: 2022-01-01 to 2024-12-31\n",
      "  Train/Test: 70%/30%\n",
      "  Monte Carlo runs: 20 (testing gradually toward 1000+)\n",
      "  Parameters: {'z_entry_threshold': 1.5, 'z_exit_threshold': 1.0, 'lookback_period': 30, 'position_size_per_pair': 0.4, 'max_holding_days': 30, 'stop_loss_z': 4.0}\n",
      "  Baseline Sharpe: 1.829\n"
     ]
    }
   ],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "\n",
    "config = {\n",
    "    'project_id': 26140717,\n",
    "    \n",
    "    # Pairs to trade\n",
    "    'pairs': [\n",
    "        {'long': 'PNC', 'short': 'KBE', 'name': 'PNC_KBE'},\n",
    "        {'long': 'ARCC', 'short': 'AMLP', 'name': 'ARCC_AMLP'},\n",
    "        {'long': 'RBA', 'short': 'SMFG', 'name': 'RBA_SMFG'},\n",
    "        {'long': 'ENB', 'short': 'WEC', 'name': 'ENB_WEC'}\n",
    "    ],\n",
    "    \n",
    "    # Total period for analysis\n",
    "    'total_period': {\n",
    "        'start': datetime(2022, 1, 1),\n",
    "        'end': datetime(2024, 12, 31)  # Use only historical data (no future dates)\n",
    "    },\n",
    "    \n",
    "    # Monte Carlo configuration\n",
    "    'train_test_split': 0.70,\n",
    "    'monte_carlo_runs': 20,  # Gradual scaling: 20 → 50 → 100 → ... → 1000+\n",
    "    'random_seed': 42,\n",
    "    \n",
    "    # Optimized parameters to test\n",
    "    'parameters': {\n",
    "        'z_entry_threshold': 1.5,\n",
    "        'z_exit_threshold': 1.0,\n",
    "        'lookback_period': 30,\n",
    "        'position_size_per_pair': 0.40,\n",
    "        'max_holding_days': 30,\n",
    "        'stop_loss_z': 4.0\n",
    "    },\n",
    "    \n",
    "    'baseline_sharpe': 1.829,\n",
    "    'initial_capital': 100000\n",
    "}\n",
    "\n",
    "# Set random seed\n",
    "if config['random_seed']:\n",
    "    random.seed(config['random_seed'])\n",
    "    np.random.seed(config['random_seed'])\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Pairs: {len(config['pairs'])}\")\n",
    "print(f\"  Period: {config['total_period']['start'].date()} to {config['total_period']['end'].date()}\")\n",
    "print(f\"  Train/Test: {config['train_test_split']*100:.0f}%/{(1-config['train_test_split'])*100:.0f}%\")\n",
    "print(f\"  Monte Carlo runs: {config['monte_carlo_runs']} (testing gradually toward 1000+)\")\n",
    "print(f\"  Parameters: {config['parameters']}\")\n",
    "print(f\"  Baseline Sharpe: {config['baseline_sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscribing to securities...\n",
      "  ✓ PNC_KBE: PNC/KBE\n",
      "  ✓ ARCC_AMLP: ARCC/AMLP\n",
      "  ✓ RBA_SMFG: RBA/SMFG\n",
      "  ✓ ENB_WEC: ENB/WEC\n",
      "\n",
      "✓ Subscribed to 4 pairs\n"
     ]
    }
   ],
   "source": [
    "# ==================== SUBSCRIBE TO SECURITIES ====================\n",
    "\n",
    "print(\"Subscribing to securities...\")\n",
    "\n",
    "symbols = {}\n",
    "for pair in config['pairs']:\n",
    "    long_sym = qb.AddEquity(pair['long'], Resolution.Daily).Symbol\n",
    "    short_sym = qb.AddEquity(pair['short'], Resolution.Daily).Symbol\n",
    "    symbols[pair['name']] = {'long': long_sym, 'short': short_sym}\n",
    "    print(f\"  ✓ {pair['name']}: {pair['long']}/{pair['short']}\")\n",
    "\n",
    "print(f\"\\n✓ Subscribed to {len(symbols)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==================== HELPER FUNCTIONS ====================\n\ndef generate_random_split(start_date, end_date, train_pct, seed=None):\n    \"\"\"Generate random train/test split for Monte Carlo - GUARANTEES test_end <= end_date\n\n    Strategy: Work backwards from end_date to ensure test period never exceeds boundary.\n    We randomly position a combined train+test window within the available range,\n    but ALWAYS anchor the test period to end no later than end_date.\n    \"\"\"\n    if seed is not None:\n        random.seed(seed)\n\n    total_days = (end_date - start_date).days\n    train_days = int(total_days * train_pct)\n    test_days = total_days - train_days\n\n    # Ensure minimum test period (60 calendar days ≈ 40-45 trading days)\n    min_test_days = 60\n    if test_days < min_test_days:\n        test_days = min_test_days\n        train_days = total_days - test_days\n\n    # NEW APPROACH: Position the test period randomly, but ALWAYS end at or before end_date\n    # Test period can start anywhere from (start_date + train_days + 1) to (end_date - test_days)\n    earliest_test_start = start_date + timedelta(days=train_days + 1)\n    latest_test_start = end_date - timedelta(days=test_days)\n\n    if latest_test_start < earliest_test_start:\n        # Not enough room - use sequential split\n        train_start = start_date\n        train_end = start_date + timedelta(days=train_days)\n        test_start = train_end + timedelta(days=1)\n        test_end = end_date  # GUARANTEED to be end_date\n    else:\n        # Random positioning of test start (but test always ends at or before end_date)\n        days_range = (latest_test_start - earliest_test_start).days\n        random_offset = random.randint(0, max(0, days_range))\n\n        test_start = earliest_test_start + timedelta(days=random_offset)\n        test_end = test_start + timedelta(days=test_days)\n\n        # CRITICAL: Ensure test_end does not exceed end_date\n        if test_end > end_date:\n            test_end = end_date\n            test_start = test_end - timedelta(days=test_days)\n\n        # Calculate training period (ends day before test starts)\n        train_end = test_start - timedelta(days=1)\n        train_start = train_end - timedelta(days=train_days)\n\n        # Ensure train_start doesn't go before start_date\n        if train_start < start_date:\n            train_start = start_date\n            train_end = test_start - timedelta(days=1)\n\n    # Final validation\n    assert test_end <= end_date, f\"BUG: test_end {test_end} exceeds end_date {end_date}\"\n    assert train_start >= start_date, f\"BUG: train_start {train_start} before start_date {start_date}\"\n\n    return train_start, train_end, test_start, test_end\n\n\ndef calculate_spread(long_prices, short_prices):\n    \"\"\"Calculate spread between two price series\"\"\"\n    return np.log(long_prices) - np.log(short_prices)\n\n\ndef calculate_zscore(spread, lookback):\n    \"\"\"Calculate z-score using rolling window\"\"\"\n    if len(spread) < lookback:\n        return pd.Series([np.nan] * len(spread), index=spread.index)\n    \n    rolling_mean = spread.rolling(window=lookback).mean()\n    rolling_std = spread.rolling(window=lookback).std(ddof=1)\n    \n    zscore = (spread - rolling_mean) / rolling_std\n    return zscore\n\n\ndef simulate_strategy(data, params):\n    \"\"\"\n    Simulate statistical arbitrage strategy on historical data\n    \n    Args:\n        data: Dict of DataFrames with price data for each pair\n        params: Strategy parameters\n    \n    Returns:\n        equity_curve: Daily portfolio values\n        trades: List of trade records\n    \"\"\"\n    capital = config['initial_capital']\n    equity_curve = []\n    trades = []\n    \n    # Get all dates (union of all pair dates)\n    all_dates = sorted(set().union(*[set(df.index) for df in data.values()]))\n    \n    # Track positions for each pair\n    positions = {pair['name']: None for pair in config['pairs']}\n    \n    for date in all_dates:\n        daily_pnl = 0\n        \n        # Process each pair\n        for pair in config['pairs']:\n            pair_name = pair['name']\n            if pair_name not in data:\n                continue\n                \n            df = data[pair_name]\n            \n            if date not in df.index:\n                continue\n            \n            # Get current prices and z-score\n            current_data = df.loc[:date]\n            if len(current_data) < params['lookback_period']:\n                continue\n            \n            long_price = df.loc[date, 'long_price']\n            short_price = df.loc[date, 'short_price']\n            z_score = df.loc[date, 'zscore']\n            \n            if np.isnan(z_score):\n                continue\n            \n            pos = positions[pair_name]\n            \n            # Check exit conditions\n            if pos is not None:\n                days_held = (date - pos['entry_date']).days\n                \n                # Calculate current P&L\n                if pos['direction'] == 'long_spread':\n                    pnl = (long_price / pos['entry_long'] - 1) * pos['long_shares'] * pos['entry_long']\n                    pnl -= (short_price / pos['entry_short'] - 1) * pos['short_shares'] * pos['entry_short']\n                else:\n                    pnl = (short_price / pos['entry_short'] - 1) * pos['short_shares'] * pos['entry_short']\n                    pnl -= (long_price / pos['entry_long'] - 1) * pos['long_shares'] * pos['entry_long']\n                \n                daily_pnl += pnl - pos['last_pnl']\n                pos['last_pnl'] = pnl\n                \n                # Exit conditions\n                exit_signal = False\n                exit_reason = None\n                \n                if abs(z_score) < params['z_exit_threshold']:\n                    exit_signal = True\n                    exit_reason = 'mean_reversion'\n                elif days_held >= params['max_holding_days']:\n                    exit_signal = True\n                    exit_reason = 'timeout'\n                elif abs(z_score) > params['stop_loss_z']:\n                    exit_signal = True\n                    exit_reason = 'stop_loss'\n                \n                if exit_signal:\n                    capital += pnl\n                    trades.append({\n                        'pair': pair_name,\n                        'entry_date': pos['entry_date'],\n                        'exit_date': date,\n                        'entry_z': pos['entry_z'],\n                        'exit_z': z_score,\n                        'pnl': pnl,\n                        'exit_reason': exit_reason,\n                        'days_held': days_held\n                    })\n                    positions[pair_name] = None\n            \n            # Check entry conditions (if no position)\n            if positions[pair_name] is None:\n                if abs(z_score) > params['z_entry_threshold']:\n                    # Calculate position sizes (dollar-neutral)\n                    pair_capital = capital * params['position_size_per_pair']\n                    \n                    if z_score > 0:  # Short spread (long short, short long)\n                        direction = 'short_spread'\n                        long_shares = pair_capital / (2 * long_price)\n                        short_shares = pair_capital / (2 * short_price)\n                    else:  # Long spread (long long, short short)\n                        direction = 'long_spread'\n                        long_shares = pair_capital / (2 * long_price)\n                        short_shares = pair_capital / (2 * short_price)\n                    \n                    positions[pair_name] = {\n                        'entry_date': date,\n                        'entry_z': z_score,\n                        'entry_long': long_price,\n                        'entry_short': short_price,\n                        'long_shares': long_shares,\n                        'short_shares': short_shares,\n                        'direction': direction,\n                        'last_pnl': 0\n                    }\n        \n        # Record equity\n        equity_curve.append({'date': date, 'equity': capital})\n    \n    return pd.DataFrame(equity_curve).set_index('date'), trades\n\n\ndef calculate_sharpe(equity_curve):\n    \"\"\"Calculate annualized Sharpe ratio\"\"\"\n    returns = equity_curve['equity'].pct_change().dropna()\n    if len(returns) == 0 or returns.std() == 0:\n        return 0.0\n    \n    sharpe = returns.mean() / returns.std() * np.sqrt(252)  # Annualized\n    return sharpe\n\n\nprint(\"✓ Helper functions loaded\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MONTE CARLO WALK-FORWARD ANALYSIS - STATISTICAL ARBITRAGE\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Monte Carlo Run 1/20\n",
      "======================================================================\n",
      "Training:  2022-07-17 to 2024-08-21 (766 days)\n",
      "Testing:   2024-08-22 to 2025-07-16 (328 days)\n",
      "\n",
      "Fetching training data...\n",
      "  ⚠ Skipping PNC_KBE: no data\n",
      "  ⚠ Skipping ARCC_AMLP: no data\n",
      "  ⚠ Skipping RBA_SMFG: no data\n",
      "  ⚠ Skipping ENB_WEC: no data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No training data available for any pair",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m days\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train_data) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo training data available for any pair\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ Fetched data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m pairs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# 3. Run strategy on TRAINING data\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: No training data available for any pair"
     ]
    }
   ],
   "source": [
    "# ==================== MONTE CARLO WALK-FORWARD ====================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MONTE CARLO WALK-FORWARD ANALYSIS - STATISTICAL ARBITRAGE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "for run in range(config['monte_carlo_runs']):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Monte Carlo Run {run + 1}/{config['monte_carlo_runs']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Generate random train/test split\n",
    "        train_start, train_end, test_start, test_end = generate_random_split(\n",
    "            config['total_period']['start'],\n",
    "            config['total_period']['end'],\n",
    "            config['train_test_split'],\n",
    "            seed=run if config['random_seed'] else None\n",
    "        )\n",
    "        \n",
    "        print(f\"Training:  {train_start.date()} to {train_end.date()} ({(train_end - train_start).days} days)\")\n",
    "        print(f\"Testing:   {test_start.date()} to {test_end.date()} ({(test_end - test_start).days} days)\")\n",
    "        \n",
    "        # 2. Fetch historical data for TRAINING period\n",
    "        print(f\"\\nFetching training data...\")\n",
    "        train_data = {}\n",
    "        for pair in config['pairs']:\n",
    "            # Fetch history - use list with single symbol to get clean DataFrame\n",
    "            long_hist = qb.History([symbols[pair['name']]['long']], train_start, train_end, Resolution.Daily)\n",
    "            short_hist = qb.History([symbols[pair['name']]['short']], train_start, train_end, Resolution.Daily)\n",
    "            \n",
    "            if long_hist.empty or short_hist.empty:\n",
    "                print(f\"  ⚠ Skipping {pair['name']}: no data\")\n",
    "                continue\n",
    "            \n",
    "            # Extract close prices - handle multi-index if present\n",
    "            if isinstance(long_hist.index, pd.MultiIndex):\n",
    "                long_close = long_hist['close'].droplevel(0)\n",
    "                short_close = short_hist['close'].droplevel(0)\n",
    "            else:\n",
    "                long_close = long_hist['close']\n",
    "                short_close = short_hist['close']\n",
    "            \n",
    "            # Create aligned DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'long_price': long_close,\n",
    "                'short_price': short_close\n",
    "            }).dropna()\n",
    "            \n",
    "            # Only require lookback period worth of data\n",
    "            if len(df) < config['parameters']['lookback_period']:\n",
    "                print(f\"  ⚠ Skipping {pair['name']}: insufficient data ({len(df)} rows, need {config['parameters']['lookback_period']})\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate spread and z-score\n",
    "            df['spread'] = np.log(df['long_price']) - np.log(df['short_price'])\n",
    "            df['zscore'] = calculate_zscore(df['spread'], config['parameters']['lookback_period'])\n",
    "            \n",
    "            train_data[pair['name']] = df\n",
    "            print(f\"  ✓ {pair['name']}: {len(df)} days\")\n",
    "        \n",
    "        if len(train_data) == 0:\n",
    "            raise ValueError(\"No training data available for any pair\")\n",
    "        \n",
    "        print(f\"  ✓ Fetched data for {len(train_data)} pairs\")\n",
    "        \n",
    "        # 3. Run strategy on TRAINING data\n",
    "        print(f\"Running strategy on training period...\")\n",
    "        train_equity, train_trades = simulate_strategy(train_data, config['parameters'])\n",
    "        train_sharpe = calculate_sharpe(train_equity)\n",
    "        print(f\"  ✓ Training Sharpe: {train_sharpe:.3f} ({len(train_trades)} trades)\")\n",
    "        \n",
    "        # 4. Fetch historical data for TESTING period\n",
    "        print(f\"\\nFetching testing data...\")\n",
    "        test_data = {}\n",
    "        for pair in config['pairs']:\n",
    "            # Fetch history\n",
    "            long_hist = qb.History([symbols[pair['name']]['long']], test_start, test_end, Resolution.Daily)\n",
    "            short_hist = qb.History([symbols[pair['name']]['short']], test_start, test_end, Resolution.Daily)\n",
    "            \n",
    "            if long_hist.empty or short_hist.empty:\n",
    "                print(f\"  ⚠ Skipping {pair['name']}: no data\")\n",
    "                continue\n",
    "            \n",
    "            # Extract close prices\n",
    "            if isinstance(long_hist.index, pd.MultiIndex):\n",
    "                long_close = long_hist['close'].droplevel(0)\n",
    "                short_close = short_hist['close'].droplevel(0)\n",
    "            else:\n",
    "                long_close = long_hist['close']\n",
    "                short_close = short_hist['close']\n",
    "            \n",
    "            # Create aligned DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'long_price': long_close,\n",
    "                'short_price': short_close\n",
    "            }).dropna()\n",
    "            \n",
    "            # Only require lookback period worth of data\n",
    "            if len(df) < config['parameters']['lookback_period']:\n",
    "                print(f\"  ⚠ Skipping {pair['name']}: insufficient data ({len(df)} rows, need {config['parameters']['lookback_period']})\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate spread and z-score\n",
    "            df['spread'] = np.log(df['long_price']) - np.log(df['short_price'])\n",
    "            df['zscore'] = calculate_zscore(df['spread'], config['parameters']['lookback_period'])\n",
    "            \n",
    "            test_data[pair['name']] = df\n",
    "            print(f\"  ✓ {pair['name']}: {len(df)} days\")\n",
    "        \n",
    "        if len(test_data) == 0:\n",
    "            raise ValueError(\"No testing data available for any pair\")\n",
    "        \n",
    "        print(f\"  ✓ Fetched data for {len(test_data)} pairs\")\n",
    "        \n",
    "        # 5. Run strategy on TESTING data\n",
    "        print(f\"Running strategy on testing period...\")\n",
    "        test_equity, test_trades = simulate_strategy(test_data, config['parameters'])\n",
    "        test_sharpe = calculate_sharpe(test_equity)\n",
    "        print(f\"  ✓ Testing Sharpe: {test_sharpe:.3f} ({len(test_trades)} trades)\")\n",
    "        \n",
    "        # 6. Calculate degradation\n",
    "        if train_sharpe > 0:\n",
    "            degradation = (train_sharpe - test_sharpe) / train_sharpe\n",
    "        else:\n",
    "            degradation = 1.0\n",
    "        \n",
    "        print(f\"  Degradation: {degradation*100:.1f}%\")\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'run': run + 1,\n",
    "            'train_start': train_start,\n",
    "            'train_end': train_end,\n",
    "            'test_start': test_start,\n",
    "            'test_end': test_end,\n",
    "            'train_sharpe': float(train_sharpe),\n",
    "            'test_sharpe': float(test_sharpe),\n",
    "            'degradation': float(degradation),\n",
    "            'train_trades': len(train_trades),\n",
    "            'test_trades': len(test_trades)\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Run {run + 1} complete\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = str(e)\n",
    "        traceback_str = traceback.format_exc()\n",
    "        print(f\"  ✗ Error in run {run + 1}: {error_msg}\")\n",
    "        print(f\"  Traceback:\\n{traceback_str}\")\n",
    "        errors.append({'run': run + 1, 'error': error_msg, 'traceback': traceback_str})\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Monte Carlo Walk-Forward Complete\")\n",
    "print(f\"  Successful runs: {len(results)}/{config['monte_carlo_runs']}\")\n",
    "print(f\"  Failed runs: {len(errors)}/{config['monte_carlo_runs']}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== ANALYSIS ====================\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"✗ No successful runs to analyze\")\n",
    "else:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AGGREGATE RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Basic statistics\n",
    "    mean_train = df_results['train_sharpe'].mean()\n",
    "    std_train = df_results['train_sharpe'].std()\n",
    "    mean_test = df_results['test_sharpe'].mean()\n",
    "    std_test = df_results['test_sharpe'].std()\n",
    "    mean_deg = df_results['degradation'].mean()\n",
    "    std_deg = df_results['degradation'].std()\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"  Baseline Sharpe (original):  {config['baseline_sharpe']:.3f}\")\n",
    "    print(f\"  Mean Training Sharpe:         {mean_train:.3f} ± {std_train:.3f}\")\n",
    "    print(f\"  Mean Testing Sharpe:          {mean_test:.3f} ± {std_test:.3f}\")\n",
    "    print(f\"  Mean Degradation:             {mean_deg*100:.1f}% ± {std_deg*100:.1f}%\")\n",
    "    \n",
    "    # ==================== BETTER OVERFITTING INDICATORS ====================\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"OVERFITTING INDICATORS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Test Sharpe Stability (Coefficient of Variation)\n",
    "    test_sharpe_cv = (std_test / mean_test) if mean_test != 0 else float('inf')\n",
    "    print(f\"\\n1. Test Sharpe Stability:\")\n",
    "    print(f\"   Coefficient of Variation: {test_sharpe_cv:.2f}\")\n",
    "    print(f\"   Interpretation: {'STABLE' if test_sharpe_cv < 0.5 else 'UNSTABLE' if test_sharpe_cv < 1.0 else 'HIGHLY UNSTABLE'}\")\n",
    "    print(f\"   (Lower is better: <0.5 stable, 0.5-1.0 moderate, >1.0 unstable)\")\n",
    "    \n",
    "    # 2. Walk-Forward Efficiency\n",
    "    wf_efficiency = mean_test / mean_train if mean_train != 0 else 0\n",
    "    print(f\"\\n2. Walk-Forward Efficiency:\")\n",
    "    print(f\"   OOS Sharpe / IS Sharpe: {wf_efficiency:.1%}\")\n",
    "    print(f\"   Interpretation: {'EXCELLENT' if wf_efficiency > 0.80 else 'GOOD' if wf_efficiency > 0.60 else 'ACCEPTABLE' if wf_efficiency > 0.40 else 'WEAK' if wf_efficiency > 0.25 else 'SEVERE OVERFIT'}\")\n",
    "    print(f\"   (Expected: 25-80% for robust strategies)\")\n",
    "    \n",
    "    # 3. Test Sharpe vs Baseline\n",
    "    test_vs_baseline = (mean_test - config['baseline_sharpe']) / config['baseline_sharpe'] if config['baseline_sharpe'] != 0 else 0\n",
    "    print(f\"\\n3. Test Sharpe vs Baseline:\")\n",
    "    print(f\"   Difference: {test_vs_baseline:+.1%}\")\n",
    "    print(f\"   Mean Test: {mean_test:.3f} vs Baseline: {config['baseline_sharpe']:.3f}\")\n",
    "    if abs(test_vs_baseline) < 0.15:\n",
    "        print(f\"   Interpretation: CONSISTENT (within 15%)\")\n",
    "    elif test_vs_baseline > 0.15:\n",
    "        print(f\"   Interpretation: UNEXPECTED - Test > Baseline (possible data issue)\")\n",
    "    else:\n",
    "        print(f\"   Interpretation: DEGRADED - Test << Baseline\")\n",
    "    \n",
    "    # 4. Trade Count Analysis\n",
    "    mean_train_trades = df_results['train_trades'].mean()\n",
    "    mean_test_trades = df_results['test_trades'].mean()\n",
    "    min_test_trades = df_results['test_trades'].min()\n",
    "    print(f\"\\n4. Trade Count Analysis:\")\n",
    "    print(f\"   Mean Training Trades: {mean_train_trades:.1f}\")\n",
    "    print(f\"   Mean Testing Trades:  {mean_test_trades:.1f}\")\n",
    "    print(f\"   Min Testing Trades:   {min_test_trades}\")\n",
    "    print(f\"   Statistical Reliability: {'GOOD' if min_test_trades >= 30 else 'MARGINAL' if min_test_trades >= 15 else 'INSUFFICIENT'}\")\n",
    "    print(f\"   (Need 30+ trades for statistical significance)\")\n",
    "    \n",
    "    # 5. Consistency Analysis (% of runs with positive test Sharpe)\n",
    "    positive_test_pct = (df_results['test_sharpe'] > 0).sum() / len(df_results)\n",
    "    print(f\"\\n5. Consistency Analysis:\")\n",
    "    print(f\"   Runs with positive test Sharpe: {(df_results['test_sharpe'] > 0).sum()}/{len(df_results)} ({positive_test_pct:.0%})\")\n",
    "    print(f\"   Interpretation: {'HIGHLY CONSISTENT' if positive_test_pct >= 0.90 else 'CONSISTENT' if positive_test_pct >= 0.75 else 'MODERATE' if positive_test_pct >= 0.60 else 'INCONSISTENT'}\")\n",
    "    \n",
    "    # 6. Sample Size Assessment\n",
    "    print(f\"\\n6. Sample Size Assessment:\")\n",
    "    print(f\"   Total runs: {len(df_results)}\")\n",
    "    print(f\"   Statistical Power: {'ROBUST' if len(df_results) >= 1000 else 'ACCEPTABLE' if len(df_results) >= 100 else 'WEAK' if len(df_results) >= 50 else 'INSUFFICIENT' if len(df_results) >= 20 else 'ANECDOTAL'}\")\n",
    "    print(f\"   Minimum required: 1000+ runs\")\n",
    "    if len(df_results) < 1000:\n",
    "        print(f\"   ⚠ WARNING: Results not statistically reliable with {len(df_results)} runs\")\n",
    "    \n",
    "    # ==================== OVERALL ASSESSMENT ====================\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"OVERALL ROBUSTNESS ASSESSMENT\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Calculate robustness score\n",
    "    score_components = []\n",
    "    \n",
    "    # Test Sharpe stability (weight: 20%)\n",
    "    if test_sharpe_cv < 0.5:\n",
    "        score_components.append(('Sharpe Stability', 20, 20))\n",
    "    elif test_sharpe_cv < 1.0:\n",
    "        score_components.append(('Sharpe Stability', 20, 10))\n",
    "    else:\n",
    "        score_components.append(('Sharpe Stability', 20, 0))\n",
    "    \n",
    "    # Walk-forward efficiency (weight: 30%)\n",
    "    if wf_efficiency > 0.80:\n",
    "        score_components.append(('WF Efficiency', 30, 30))\n",
    "    elif wf_efficiency > 0.60:\n",
    "        score_components.append(('WF Efficiency', 30, 25))\n",
    "    elif wf_efficiency > 0.40:\n",
    "        score_components.append(('WF Efficiency', 30, 15))\n",
    "    elif wf_efficiency > 0.25:\n",
    "        score_components.append(('WF Efficiency', 30, 5))\n",
    "    else:\n",
    "        score_components.append(('WF Efficiency', 30, 0))\n",
    "    \n",
    "    # Test vs baseline (weight: 20%)\n",
    "    if abs(test_vs_baseline) < 0.15:\n",
    "        score_components.append(('Test vs Baseline', 20, 20))\n",
    "    elif abs(test_vs_baseline) < 0.30:\n",
    "        score_components.append(('Test vs Baseline', 20, 10))\n",
    "    else:\n",
    "        score_components.append(('Test vs Baseline', 20, 0))\n",
    "    \n",
    "    # Trade count (weight: 15%)\n",
    "    if min_test_trades >= 30:\n",
    "        score_components.append(('Trade Count', 15, 15))\n",
    "    elif min_test_trades >= 15:\n",
    "        score_components.append(('Trade Count', 15, 8))\n",
    "    else:\n",
    "        score_components.append(('Trade Count', 15, 0))\n",
    "    \n",
    "    # Consistency (weight: 15%)\n",
    "    if positive_test_pct >= 0.90:\n",
    "        score_components.append(('Consistency', 15, 15))\n",
    "    elif positive_test_pct >= 0.75:\n",
    "        score_components.append(('Consistency', 15, 12))\n",
    "    elif positive_test_pct >= 0.60:\n",
    "        score_components.append(('Consistency', 15, 8))\n",
    "    else:\n",
    "        score_components.append(('Consistency', 15, 0))\n",
    "    \n",
    "    total_score = sum(s[2] for s in score_components)\n",
    "    max_score = sum(s[1] for s in score_components)\n",
    "    \n",
    "    print(\"Score Breakdown:\")\n",
    "    for name, max_pts, earned_pts in score_components:\n",
    "        print(f\"  {name}: {earned_pts}/{max_pts}\")\n",
    "    \n",
    "    print(f\"\\nTotal Robustness Score: {total_score}/{max_score} ({total_score/max_score*100:.0f}%)\")\n",
    "    \n",
    "    # Final decision\n",
    "    if len(df_results) < 1000:\n",
    "        decision = \"INSUFFICIENT_SAMPLES\"\n",
    "        reason = f\"Only {len(df_results)} runs (need 1000+ for validation)\"\n",
    "        recommendation = \"Continue scaling to 1000+ runs before making conclusion\"\n",
    "    elif total_score >= 85:\n",
    "        decision = \"ROBUST_STRATEGY\"\n",
    "        reason = f\"Score {total_score}/{max_score} - strong generalization\"\n",
    "        recommendation = \"Strategy passes validation - ready for paper trading\"\n",
    "    elif total_score >= 70:\n",
    "        decision = \"PROCEED_WITH_CAUTION\"\n",
    "        reason = f\"Score {total_score}/{max_score} - acceptable but not excellent\"\n",
    "        recommendation = \"Strategy shows reasonable robustness - additional validation recommended\"\n",
    "    elif total_score >= 50:\n",
    "        decision = \"WEAK_ROBUSTNESS\"\n",
    "        reason = f\"Score {total_score}/{max_score} - multiple concerns\"\n",
    "        recommendation = \"Strategy shows weak generalization - use with caution or re-optimize\"\n",
    "    else:\n",
    "        decision = \"ABANDON_STRATEGY\"\n",
    "        reason = f\"Score {total_score}/{max_score} - severe overfitting\"\n",
    "        recommendation = \"Strategy fails validation - consider new hypothesis\"\n",
    "    \n",
    "    print(f\"\\n✓ Decision: {decision}\")\n",
    "    print(f\"  Reason: {reason}\")\n",
    "    print(f\"  Recommendation: {recommendation}\")\n",
    "    \n",
    "    # Save results\n",
    "    output_data = {\n",
    "        'strategy': 'Statistical Arbitrage Pairs Trading',\n",
    "        'hypothesis_id': 5,\n",
    "        'project_id': config['project_id'],\n",
    "        'summary': {\n",
    "            'sample_size': len(results),\n",
    "            'successful_runs': len(results),\n",
    "            'failed_runs': len(errors),\n",
    "            'mean_train_sharpe': float(mean_train),\n",
    "            'std_train_sharpe': float(std_train),\n",
    "            'mean_test_sharpe': float(mean_test),\n",
    "            'std_test_sharpe': float(std_test),\n",
    "            'mean_degradation': float(mean_deg),\n",
    "            'std_degradation': float(std_deg),\n",
    "            'test_sharpe_cv': float(test_sharpe_cv),\n",
    "            'wf_efficiency': float(wf_efficiency),\n",
    "            'test_vs_baseline_pct': float(test_vs_baseline),\n",
    "            'mean_train_trades': float(mean_train_trades),\n",
    "            'mean_test_trades': float(mean_test_trades),\n",
    "            'min_test_trades': int(min_test_trades),\n",
    "            'positive_test_pct': float(positive_test_pct),\n",
    "            'robustness_score': int(total_score),\n",
    "            'max_score': int(max_score),\n",
    "            'decision': decision,\n",
    "            'reason': reason,\n",
    "            'recommendation': recommendation\n",
    "        },\n",
    "        'detailed_results': results,\n",
    "        'errors': errors\n",
    "    }\n",
    "    \n",
    "    filename = f\"walkforward_stat_arb_h5_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(output_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"\\n✓ Results saved to: {filename}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MONTE CARLO WALK-FORWARD ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ==================== GENERATE HTML REPORT ====================\n\nif len(results) > 0:\n    df_results = pd.DataFrame(results)\n    \n    # Recalculate metrics for HTML\n    mean_train = df_results['train_sharpe'].mean()\n    std_train = df_results['train_sharpe'].std()\n    mean_test = df_results['test_sharpe'].mean()\n    std_test = df_results['test_sharpe'].std()\n    mean_deg = df_results['degradation'].mean()\n    std_deg = df_results['degradation'].std()\n    test_sharpe_cv = (std_test / mean_test) if mean_test != 0 else float('inf')\n    wf_efficiency = mean_test / mean_train if mean_train != 0 else 0\n    test_vs_baseline = (mean_test - config['baseline_sharpe']) / config['baseline_sharpe'] if config['baseline_sharpe'] != 0 else 0\n    mean_train_trades = df_results['train_trades'].mean()\n    mean_test_trades = df_results['test_trades'].mean()\n    min_test_trades = df_results['test_trades'].min()\n    positive_test_pct = (df_results['test_sharpe'] > 0).sum() / len(df_results)\n    \n    # Generate HTML\n    html = f\"\"\"\n    <!DOCTYPE html>\n    <html>\n    <head>\n        <title>Monte Carlo Walk-Forward Validation - Statistical Arbitrage</title>\n        <style>\n            body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 40px; background: #f5f5f5; }}\n            .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 40px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n            h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}\n            h2 {{ color: #34495e; margin-top: 30px; border-bottom: 2px solid #ecf0f1; padding-bottom: 8px; }}\n            h3 {{ color: #7f8c8d; margin-top: 20px; }}\n            .metric-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 20px; margin: 20px 0; }}\n            .metric-card {{ background: #ecf0f1; padding: 20px; border-radius: 8px; border-left: 4px solid #3498db; }}\n            .metric-label {{ font-size: 14px; color: #7f8c8d; text-transform: uppercase; margin-bottom: 5px; }}\n            .metric-value {{ font-size: 32px; font-weight: bold; color: #2c3e50; }}\n            .metric-subtext {{ font-size: 14px; color: #95a5a6; margin-top: 5px; }}\n            table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n            th {{ background: #34495e; color: white; padding: 12px; text-align: left; }}\n            td {{ padding: 10px; border-bottom: 1px solid #ecf0f1; }}\n            tr:hover {{ background: #f8f9fa; }}\n            .status-good {{ color: #27ae60; font-weight: bold; }}\n            .status-warn {{ color: #f39c12; font-weight: bold; }}\n            .status-bad {{ color: #e74c3c; font-weight: bold; }}\n            .decision-box {{ background: #3498db; color: white; padding: 30px; border-radius: 8px; margin: 30px 0; text-align: center; }}\n            .decision-box h2 {{ color: white; border: none; }}\n            .progress-bar {{ width: 100%; background: #ecf0f1; height: 30px; border-radius: 15px; overflow: hidden; margin: 10px 0; }}\n            .progress-fill {{ background: linear-gradient(90deg, #3498db, #2ecc71); height: 100%; text-align: center; line-height: 30px; color: white; font-weight: bold; }}\n        </style>\n    </head>\n    <body>\n        <div class=\"container\">\n            <h1>Monte Carlo Walk-Forward Validation Report</h1>\n            <p><strong>Strategy:</strong> Hypothesis 5 - Statistical Arbitrage Pairs Trading</p>\n            <p><strong>Project ID:</strong> {config['project_id']}</p>\n            <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n            \n            <h2>Configuration</h2>\n            <ul>\n                <li><strong>Pairs Tested:</strong> {len(config['pairs'])} ({', '.join([p['name'] for p in config['pairs']])})</li>\n                <li><strong>Date Range:</strong> {config['total_period']['start'].date()} to {config['total_period']['end'].date()}</li>\n                <li><strong>Train/Test Split:</strong> {config['train_test_split']*100:.0f}% / {(1-config['train_test_split'])*100:.0f}%</li>\n                <li><strong>Monte Carlo Runs:</strong> {len(results)} successful / {len(errors)} failed</li>\n                <li><strong>Parameters:</strong> z_entry={config['parameters']['z_entry_threshold']}, z_exit={config['parameters']['z_exit_threshold']}, lookback={config['parameters']['lookback_period']}</li>\n            </ul>\n            \n            <h2>Performance Summary</h2>\n            <div class=\"metric-grid\">\n                <div class=\"metric-card\">\n                    <div class=\"metric-label\">Baseline Sharpe (Original)</div>\n                    <div class=\"metric-value\">{config['baseline_sharpe']:.3f}</div>\n                    <div class=\"metric-subtext\">From optimization</div>\n                </div>\n                <div class=\"metric-card\">\n                    <div class=\"metric-label\">Mean Training Sharpe</div>\n                    <div class=\"metric-value\">{mean_train:.3f}</div>\n                    <div class=\"metric-subtext\">± {std_train:.3f}</div>\n                </div>\n                <div class=\"metric-card\">\n                    <div class=\"metric-label\">Mean Testing Sharpe</div>\n                    <div class=\"metric-value\">{mean_test:.3f}</div>\n                    <div class=\"metric-subtext\">± {std_test:.3f}</div>\n                </div>\n                <div class=\"metric-card\">\n                    <div class=\"metric-label\">Mean Degradation</div>\n                    <div class=\"metric-value\">{mean_deg*100:.1f}%</div>\n                    <div class=\"metric-subtext\">± {std_deg*100:.1f}%</div>\n                </div>\n            </div>\n            \n            <h2>Overfitting Indicators</h2>\n            <table>\n                <tr>\n                    <th>Indicator</th>\n                    <th>Value</th>\n                    <th>Interpretation</th>\n                    <th>Status</th>\n                </tr>\n                <tr>\n                    <td>1. Test Sharpe Stability (CV)</td>\n                    <td>{test_sharpe_cv:.2f}</td>\n                    <td>{'STABLE' if test_sharpe_cv < 0.5 else 'MODERATE' if test_sharpe_cv < 1.0 else 'UNSTABLE'}</td>\n                    <td class=\"{'status-good' if test_sharpe_cv < 0.5 else 'status-warn' if test_sharpe_cv < 1.0 else 'status-bad'}\">{'✓' if test_sharpe_cv < 0.5 else '⚠' if test_sharpe_cv < 1.0 else '✗'}</td>\n                </tr>\n                <tr>\n                    <td>2. Walk-Forward Efficiency</td>\n                    <td>{wf_efficiency:.1%}</td>\n                    <td>{'EXCELLENT' if wf_efficiency > 0.80 else 'GOOD' if wf_efficiency > 0.60 else 'ACCEPTABLE' if wf_efficiency > 0.40 else 'WEAK'}</td>\n                    <td class=\"{'status-good' if wf_efficiency > 0.60 else 'status-warn' if wf_efficiency > 0.40 else 'status-bad'}\">{'✓' if wf_efficiency > 0.60 else '⚠' if wf_efficiency > 0.40 else '✗'}</td>\n                </tr>\n                <tr>\n                    <td>3. Test vs Baseline</td>\n                    <td>{test_vs_baseline:+.1%}</td>\n                    <td>{'CONSISTENT' if abs(test_vs_baseline) < 0.15 else 'DEGRADED' if test_vs_baseline < -0.15 else 'UNEXPECTED'}</td>\n                    <td class=\"{'status-good' if abs(test_vs_baseline) < 0.15 else 'status-warn' if abs(test_vs_baseline) < 0.30 else 'status-bad'}\">{'✓' if abs(test_vs_baseline) < 0.15 else '⚠' if abs(test_vs_baseline) < 0.30 else '✗'}</td>\n                </tr>\n                <tr>\n                    <td>4. Trade Count (min test)</td>\n                    <td>{min_test_trades}</td>\n                    <td>{'GOOD' if min_test_trades >= 30 else 'MARGINAL' if min_test_trades >= 15 else 'INSUFFICIENT'}</td>\n                    <td class=\"{'status-good' if min_test_trades >= 30 else 'status-warn' if min_test_trades >= 15 else 'status-bad'}\">{'✓' if min_test_trades >= 30 else '⚠' if min_test_trades >= 15 else '✗'}</td>\n                </tr>\n                <tr>\n                    <td>5. Consistency (positive runs)</td>\n                    <td>{positive_test_pct:.0%}</td>\n                    <td>{'HIGHLY CONSISTENT' if positive_test_pct >= 0.90 else 'CONSISTENT' if positive_test_pct >= 0.75 else 'MODERATE' if positive_test_pct >= 0.60 else 'INCONSISTENT'}</td>\n                    <td class=\"{'status-good' if positive_test_pct >= 0.75 else 'status-warn' if positive_test_pct >= 0.60 else 'status-bad'}\">{'✓' if positive_test_pct >= 0.75 else '⚠' if positive_test_pct >= 0.60 else '✗'}</td>\n                </tr>\n                <tr>\n                    <td>6. Sample Size</td>\n                    <td>{len(results)} runs</td>\n                    <td>{'ROBUST' if len(results) >= 1000 else 'ACCEPTABLE' if len(results) >= 100 else 'WEAK' if len(results) >= 50 else 'INSUFFICIENT'}</td>\n                    <td class=\"{'status-good' if len(results) >= 1000 else 'status-warn' if len(results) >= 100 else 'status-bad'}\">{'✓' if len(results) >= 1000 else '⚠' if len(results) >= 100 else '✗'}</td>\n                </tr>\n            </table>\n            \n            <h2>Robustness Score</h2>\n            <p>Composite score based on all overfitting indicators (weighted):</p>\n    \"\"\"\n    \n    # Calculate score components (same logic as analysis cell)\n    score_components = []\n    if test_sharpe_cv < 0.5:\n        score_components.append(('Sharpe Stability', 20, 20))\n    elif test_sharpe_cv < 1.0:\n        score_components.append(('Sharpe Stability', 20, 10))\n    else:\n        score_components.append(('Sharpe Stability', 20, 0))\n    \n    if wf_efficiency > 0.80:\n        score_components.append(('WF Efficiency', 30, 30))\n    elif wf_efficiency > 0.60:\n        score_components.append(('WF Efficiency', 30, 25))\n    elif wf_efficiency > 0.40:\n        score_components.append(('WF Efficiency', 30, 15))\n    elif wf_efficiency > 0.25:\n        score_components.append(('WF Efficiency', 30, 5))\n    else:\n        score_components.append(('WF Efficiency', 30, 0))\n    \n    if abs(test_vs_baseline) < 0.15:\n        score_components.append(('Test vs Baseline', 20, 20))\n    elif abs(test_vs_baseline) < 0.30:\n        score_components.append(('Test vs Baseline', 20, 10))\n    else:\n        score_components.append(('Test vs Baseline', 20, 0))\n    \n    if min_test_trades >= 30:\n        score_components.append(('Trade Count', 15, 15))\n    elif min_test_trades >= 15:\n        score_components.append(('Trade Count', 15, 8))\n    else:\n        score_components.append(('Trade Count', 15, 0))\n    \n    if positive_test_pct >= 0.90:\n        score_components.append(('Consistency', 15, 15))\n    elif positive_test_pct >= 0.75:\n        score_components.append(('Consistency', 15, 12))\n    elif positive_test_pct >= 0.60:\n        score_components.append(('Consistency', 15, 8))\n    else:\n        score_components.append(('Consistency', 15, 0))\n    \n    total_score = sum(s[2] for s in score_components)\n    max_score = sum(s[1] for s in score_components)\n    score_pct = total_score / max_score * 100\n    \n    html += f\"\"\"\n            <table>\n                <tr><th>Component</th><th>Weight</th><th>Earned</th></tr>\n    \"\"\"\n    \n    for name, max_pts, earned_pts in score_components:\n        html += f\"<tr><td>{name}</td><td>{max_pts}</td><td>{earned_pts}</td></tr>\"\n    \n    html += f\"\"\"\n                <tr style=\"background: #ecf0f1; font-weight: bold;\">\n                    <td>TOTAL</td>\n                    <td>{max_score}</td>\n                    <td>{total_score}</td>\n                </tr>\n            </table>\n            \n            <div class=\"progress-bar\">\n                <div class=\"progress-fill\" style=\"width: {score_pct}%\">{score_pct:.0f}%</div>\n            </div>\n    \"\"\"\n    \n    # Decision box\n    if len(results) < 1000:\n        decision = \"INSUFFICIENT_SAMPLES\"\n        reason = f\"Only {len(results)} runs (need 1000+ for validation)\"\n        recommendation = \"Continue scaling to 1000+ runs before making conclusion\"\n        box_color = \"#f39c12\"\n    elif total_score >= 85:\n        decision = \"ROBUST_STRATEGY\"\n        reason = f\"Score {total_score}/{max_score} - strong generalization\"\n        recommendation = \"Strategy passes validation - ready for paper trading\"\n        box_color = \"#27ae60\"\n    elif total_score >= 70:\n        decision = \"PROCEED_WITH_CAUTION\"\n        reason = f\"Score {total_score}/{max_score} - acceptable but not excellent\"\n        recommendation = \"Strategy shows reasonable robustness - additional validation recommended\"\n        box_color = \"#3498db\"\n    elif total_score >= 50:\n        decision = \"WEAK_ROBUSTNESS\"\n        reason = f\"Score {total_score}/{max_score} - multiple concerns\"\n        recommendation = \"Strategy shows weak generalization - use with caution or re-optimize\"\n        box_color = \"#f39c12\"\n    else:\n        decision = \"ABANDON_STRATEGY\"\n        reason = f\"Score {total_score}/{max_score} - severe overfitting\"\n        recommendation = \"Strategy fails validation - consider new hypothesis\"\n        box_color = \"#e74c3c\"\n    \n    html += f\"\"\"\n            <div class=\"decision-box\" style=\"background: {box_color};\">\n                <h2>✓ DECISION: {decision}</h2>\n                <p><strong>Reason:</strong> {reason}</p>\n                <p><strong>Recommendation:</strong> {recommendation}</p>\n            </div>\n            \n            <h2>Detailed Results</h2>\n            <table>\n                <tr>\n                    <th>Run</th>\n                    <th>Train Period</th>\n                    <th>Test Period</th>\n                    <th>Train Sharpe</th>\n                    <th>Test Sharpe</th>\n                    <th>Degradation</th>\n                    <th>Train Trades</th>\n                    <th>Test Trades</th>\n                </tr>\n    \"\"\"\n    \n    for result in results[:20]:  # Show first 20 runs\n        html += f\"\"\"\n                <tr>\n                    <td>{result['run']}</td>\n                    <td>{result['train_start'].date()} to {result['train_end'].date()}</td>\n                    <td>{result['test_start'].date()} to {result['test_end'].date()}</td>\n                    <td>{result['train_sharpe']:.3f}</td>\n                    <td>{result['test_sharpe']:.3f}</td>\n                    <td>{result['degradation']*100:.1f}%</td>\n                    <td>{result['train_trades']}</td>\n                    <td>{result['test_trades']}</td>\n                </tr>\n        \"\"\"\n    \n    if len(results) > 20:\n        html += f\"<tr><td colspan='8' style='text-align: center; color: #7f8c8d;'>... and {len(results)-20} more runs (see JSON file for complete data)</td></tr>\"\n    \n    html += \"\"\"\n            </table>\n        </div>\n    </body>\n    </html>\n    \"\"\"\n    \n    # Save HTML\n    html_filename = f\"walkforward_report_h5_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n    with open(html_filename, 'w') as f:\n        f.write(html)\n    \n    print(f\"\\n✓ HTML report saved to: {html_filename}\")\n    print(f\"  Open this file in your browser to view full results\")\n    \n    # Display message\n    from IPython.display import HTML, display\n    display(HTML(f\"\"\"\n    <div style=\"background: #d4edda; border: 2px solid #28a745; padding: 20px; border-radius: 8px; margin: 20px 0;\">\n        <h3 style=\"color: #155724; margin: 0 0 10px 0;\">✓ HTML Report Generated</h3>\n        <p style=\"margin: 5px 0;\"><strong>File:</strong> {html_filename}</p>\n        <p style=\"margin: 5px 0;\"><strong>Location:</strong> Current directory</p>\n        <p style=\"margin: 5px 0;\"><strong>View:</strong> Download and open in your web browser</p>\n        <p style=\"margin: 15px 0 0 0; color: #155724;\">\n            <em>The HTML report shows all results without truncation, including full metrics, \n            overfitting indicators, robustness score, and detailed run-by-run data.</em>\n        </p>\n    </div>\n    \"\"\"))\n    \nelse:\n    print(\"No results to generate HTML report\")\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation-Py-Default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}